<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Ilias Lolis' Blog Blog</title>
        <link>https://ilolis.github.io/</link>
        <description>Ilias Lolis' Blog Blog</description>
        <lastBuildDate>Wed, 15 Feb 2023 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Redis Durability]]></title>
            <link>https://ilolis.github.io/redis-durability</link>
            <guid>https://ilolis.github.io/redis-durability</guid>
            <pubDate>Wed, 15 Feb 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[Redis Fundamentals]]></description>
            <content:encoded><![CDATA[<h3 class="anchor anchorWithStickyNavbar_LWe7" id="redis-fundamentals">Redis Fundamentals<a href="#redis-fundamentals" class="hash-link" aria-label="Direct link to Redis Fundamentals" title="Direct link to Redis Fundamentals">â€‹</a></h3><p>Redis is a high-performance, distributed, in-memory data store that can be used as a database, cache or message broker. It is an open-source, NoSQL database that is designed to deliver high performance and low latency access to data. The core difference between Redis and a traditional database such as Postgres, MySQL and DynamoDB is that Redis stores data in memory and not in disk, a <em>feature</em> that gives Redis ultra fast response times.</p><p>However, the approach of storing data in-memory can be prone to data loss in the event of a system crash or power failure. In contrast, storing data persistently on disk provides durability, but at the cost of slower access times due to disk I/O. In this article, we will discuss methods for configuring Redis to be more resilient, as an out-of-the-box configuration of Redis could result in complete data loss if your Redis instance crashes.</p><p>There exist several methods to safeguard against a data loss. However, it is commonly misunderstood that enabling replication in Redis suffices to solve this problem. Yet, this notion does not always hold true. Prior to exploring the various options available for ensuring the durability of Redis as a database, let's first examine how Redis replication works.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="redis-replication">Redis Replication<a href="#redis-replication" class="hash-link" aria-label="Direct link to Redis Replication" title="Direct link to Redis Replication">â€‹</a></h3><p>Redis provides a replication mechanism that allows it to withstand a node failure increasing the availability and the throughput of the system. The default replication strategy of Redis is based on a master-replica model, where one Redis instance acts as the master and one or more Redis instances act as replicas. The master continuously sends commands and data to its replicas, which replicate the master's data in near real-time. When a write operation occurs on the master, the operation is first written to the master's in-memory database, and then transmitted <strong>asynchronously</strong> to all the connected replicas. The replicas then execute the same operation in their own databases, which allows them to maintain a copy of the master's data and being in-sync. </p><p>In case of a master node failure, Redis supports automatic failover, where a replica can be promoted to a master. Redis achieves this by monitoring the health of nodes and by initiating a failover if necessary. When Redis detects that the master is down, it selects one replica to promote to master and reconfigures the other replicas to replicate from the new master. This process is designed to be automatic and fast, allowing for minimal downtime in the event of a master failure.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="the-catch">The catch<a href="#the-catch" class="hash-link" aria-label="Direct link to The catch" title="Direct link to The catch">â€‹</a></h4><p>The catch in the above strategy is the fact that the replication of the data between the master and the replica happens asynchronously. This means that when a client issues a write command to a Redis master, the master will acknowledge the write operation and then asynchronously update the replicas. If the master crashes after sending the acknowledgement to the client but <strong>before</strong> sending the write command to the replicas, the failover mechanism will be triggered and a slave will be promoted to a master, <strong>without</strong> including the latest write command!</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-mitigate">How to mitigate<a href="#how-to-mitigate" class="hash-link" aria-label="Direct link to How to mitigate" title="Direct link to How to mitigate">â€‹</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="option-1-use-wait-n-t">Option 1: Use <code>WAIT N T</code><a href="#option-1-use-wait-n-t" class="hash-link" aria-label="Direct link to option-1-use-wait-n-t" title="Direct link to option-1-use-wait-n-t">â€‹</a></h4><p>The <code>WAIT N T</code> command instructs the master to replicate the write request to at least <code>N</code> replicas and for a maximum of <code>T</code> milliseconds before acknowledging the write request to the client. </p><p>In this scenario, if <code>N</code> equals to the number of replicas, then the write operation will only be considered complete when all replicas have received the write and acknowledge it. This approach ensures that all replicas get the write command and in case of a failover all of the replicas will be in-sync with the master, so that no-data will be lost.</p><p>If the N parameter in the <code>WAIT</code> command is set to a value less than the total number of replicas, then the write operation will only be applied to <code>N</code> replicas, and not all replicas in the system will have the latest write. If a replica that did not receive the latest write is promoted to a master during a failover the latest write will be lost. Therefore, it's important to set the <code>N</code> parameter to a value that is equal to the number of replicas to ensure that all replicas receive the latest write and to prevent data loss.</p><p>However, it's important to note that this approach comes with significant performance  trade-off. Waiting for all your replicas to acknowledge a write operation can result in increased latency and reduced throughput, especially when your application is read-heavy requiring many replicas. </p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="option-2-make-redis-a-persistence-database">Option 2: Make Redis a persistence database<a href="#option-2-make-redis-a-persistence-database" class="hash-link" aria-label="Direct link to Option 2: Make Redis a persistence database" title="Direct link to Option 2: Make Redis a persistence database">â€‹</a></h4><p>Since Redis stores all of your data in-memory, you should be aware that in the above solution, if the master and all of the replicas fail due to hardware issues, you will lose your data permanently. To make your Redis durable, you can configure Redis to dump your data to durable storage such as an SSD or an HDD. </p><p>Redis provides two mechanisms for persistence: RDB (Redis Database) and AOF (Append Only File). RDB persistence is a point-in-time snapshot of the entire Redis dataset. It works by periodically saving the dataset to disk as a binary file. This binary file can be used to restore the dataset in case of a Redis restart. RDB persistence is suitable for scenarios where you can afford to lose some data since the persistence is performed at a specific interval (for example every <code>n</code> seconds). This method does not cause any significant response latency for the write commands, since saving the dataset to the disk happens asynchronously, but it does not guarantee that the dumped dataset will contain all of the write operations. </p><p>AOF persistence, on the other hand, logs all the write operations to a file. The AOF file contains a sequence of write operations that can be replayed to reconstruct the dataset. AOF persistence is suitable for scenarios where you cannot afford to lose any data, as it logs every write operation before acknowledging it to the client. </p><p>Although writing your dataset to disk provides protection in the event of Redis failure, it also has a significant disadvantage: increased latency and reduced throughput. However, it's important to keep in mind that Redis is primarily an in-memory database, so enabling the AOF (Append-Only File) functionality may seem counter-intuitive. <strong>If durability is a top priority, consider using an on-disk database such as DynamoDB or MongoDB instead.</strong> These databases are optimized for durability and can provide more comprehensive data protection.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-correctly-mitigate-in-aws">How to correctly mitigate in AWS<a href="#how-to-correctly-mitigate-in-aws" class="hash-link" aria-label="Direct link to How to correctly mitigate in AWS" title="Direct link to How to correctly mitigate in AWS">â€‹</a></h3><p>By implementing the AOF feature in Redis, all writes are stored on disk, ensuring durability. Meanwhile, subsequent reads are retrieved from memory, resulting in faster read speeds compared to traditional on-disk databases. However, write operations are still as slow as on-disk database systems.</p><p>By now, you should be familiar that making Redis a durable database might raise some eyebrows, especially when you have <em>great</em> alternatives to choose from. For example, DynamoDB provides durability out-of-the-box and has a cool feature named DynamoDB Accelerator (DAX). DAX is a fully managed, in-memory cache layer that sits between your application and DynamoDB, making your read operations as fast as what Redis can deliver!</p><p>If I haven't yet convinced you to not make Redis a durable database, then let's discuss how you can achieve that in AWS. AWS does not let you enable the AOF feature if you have Multi-AZ deployment, so you are out of luck. Thankfully, a different service called AWS MemoryDB solves this problem. AWS markets MemoryDB as a "Redis-compatible, durable, in-memory database service for ultra-fast performance" that "stores data durably across multiple Availability Zones (AZs) <strong>using a distributed transactional log</strong> <!-- -->[emphasis mine]<!-- --> to enable fast failover, database recovery, and node restarts".  </p><p>MemoryDB achieves durability by enabling the AOF feature we discussed earlier. The Append-Only-File is distributed across different Availability Zones which ensures that your data isn't lost, even if an AZ becomes offline. In the event where all of your Redis instances fail, MemoryDB will create new instances and restore all the data from the previous instances by executing the AOF. Moreover, in the scenario that only the master node fails and an out-of-date replica is promoted to master, MemoryDB will detect that the new master does not contain all of the data and trigger an execution of the AOF on the new master to prevent any data loss!</p><p>The bad case about MemoryDB is that it is very expensive. At the time of writing, the price of <code>db.r6g.large</code> with on-demand pricing for the Ireland region costs $0.344/hour which totals to about $260/month. The same instance in ElastiCache costs only about $170/month, which is significantly cheaper. Moreover, MemoryDB changes $0.20 for each GB of data you write to your Redis, which isn't significant, but if your application is write-heavy, then this cost will add up quickly.</p><p>I guess, durability comes at a cost.</p>]]></content:encoded>
            <category>hola</category>
            <category>welcome</category>
        </item>
        <item>
            <title><![CDATA[Welcome To My Blog!]]></title>
            <link>https://ilolis.github.io/welcome-to-my-blog</link>
            <guid>https://ilolis.github.io/welcome-to-my-blog</guid>
            <pubDate>Wed, 15 Feb 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[Welcome to my blog! ðŸ§¡]]></description>
            <content:encoded><![CDATA[<p>Welcome to my blog! ðŸ§¡</p><p>If you're passionate about software engineering and microservices, you're in the right place! I've always been fascinated by the potential of microservices architecture and its impact on building scalable and resilient applications!</p><p>In this blog, I will be sharing my knowledge, experience, and insights on various topics related to software engineering. I'll cover a range of topics, including best practices for designing and implementing microservices, tools and technologies for your development process, things to watch out and the latest trends (and not) in the software engineering industry. Also, I might write a few things about embedded stuff. ðŸ˜Š</p><p>So, whether you're looking to improve your skills as a software engineer, or you're simply interested in learning more about microservices, I invite you to keep an eye on my blog! </p><p>I hope that you'll find something useful and interesting here.</p><p>See you!</p>]]></content:encoded>
            <category>hola</category>
            <category>welcome</category>
        </item>
    </channel>
</rss>